---
categories: technology
layout: post
---

- Table
{:toc}

# 语言

- 语言：可能字符串的集合
- 字符串：有限符号序列，每个符号都来自相同的有限字符集
- 字符集：所有可能符号组成的集合

# Lexer

Lexer的作用是：

- 从源代码中去除不必要的空白字符和注释
- 将源代码的输入分解为Token

Lexer一般可以通过正则表达式来实现

## 正则表达式

正则表达式基本元素

- `a`， 字面量，匹配自身
- `@`， 空字符串（正式写法是$\epsilon$，这里只是出于简化的目的）
- `A|B`，A或B
- `AB`，先A后B
- `A*`，匹配任意多次A

其余扩展元素可以通过基本元素的组合实现

- `A?`，等价于`A|@`
- `A+`，等价于`AA*`
- `[ABC]`，等价于`A|B|C`
- `[a-cA-B]`，等价于`[abcAB]`

### 匹配规则

给定一个正则表达式和一个输入字符串，可能存在不同的匹配方案。比如`if8`可以匹配一个标识符，也可以先后匹配`if`和`8`。下面是为了确定匹配关系的规则：

- 最长匹配：最长可以匹配任意正则表达式的输入前缀，将作为下一个token
- 规则优先级：对于特定的前缀，如果有多个正则表达式可以匹配，则第一个正则表达式将决定token类型。

### 正则表达式的实现

可以通过有限自动机（finite automaton）来实现正则表达式。

自动机是一副有向图，每个状态对应图中的一个结点，如果存在符号`x`使得从状态`A`向状态`B`迁移，则从`A`到`B`有一条标记`x`的有向边。

自动机会有两个特殊状态：开始状态（start state）和中止状态（final state）。每次匹配都从开始状态出发，如果最终到达中止状态则匹配输入字符。

如果自动机中每个状态的出边上标记的符号都不同，那么自动机为确定有限自动机（deterministic finite automaton），否则为非确定有限自动机（nondeterministic finite automaton）。

构建NFA的算法可以采用[Thompson算法](https://en.wikipedia.org/wiki/Thompson%27s_construction)。

在得到了NFA后，由于NFA是不确定的，因此在匹配的时候需要枚举所有可能性，会降低性能。观察可以发现对于一段输入，NFA可能会处于多个状态，换言之，处于某个状态集合，而对于某个符号，NFA会从某个特定的状态集合转移到另外一个特定的状态集合。因此如果我们将NFA的状态集合作为DFA的状态，那么就可以构建一个DFA。拥有$n$个状态的NFA的状态集合是$2^n$级别的，但是实践中可达的状态集合只有大约$n$个，因此这个方法是可行的。

# Parsing

Parsing的作用是解析语法，它的输入是Token序列，输出是语法树。

## 上下文无关语法

上下文无关语法拥有一系列下面形式的产生式：

```
symbol -> symbol ... symbol
```

左边是一个符号，右边可以是任意数目的符号。符号分为两类：

- 终止符（terminal）：某个特定的Token
- 非终止符（nonterminal）：出现在某个产生式的左边

其中开始符`S`是一个特殊的非终止符。同时为了方便解析，需要引入一个文件结束符号`$`，以及新的开始符`S'->S$`。

## 展开（derivation）

展开指从开始符展开为整个字符串。展开分为两类：

- 最左展开：每次选择最左边的非终止符展开
- 最右展开：每次选择最右边的非终止符展开

## 解析树（Parse Tree）

在展开的时候，每次替换非终止符时，都将原来的非终止符和展开的右式中的符号连接，形成的树为解析树。

## 歧义语法

如果一个语法可能将相同的字符串解析为两颗不同的解析树，那么这个语法是歧义的。一般有歧义的语法可以通过引入额外的非终止符来去除歧义，但是依旧存在一些语法无法消除歧义，这种语法一般不适合作为编程语言。

比如只有加法和乘法的语法定义如下：

```
S -> E$

E -> num
E -> E + E
E -> E * E
```

前者对于`1+2*3`生成的解析树有两种可能：

```
E-------
|  |   |  
1  +   E----
       | | |
       2 * 3
```

和

```
E------
|  |  |  
|  *  3
|
E------   
|  |  |
1  +  2
```

通过引入新的非终止符可以得到

```
S -> E$

M -> num
M -> M * M

E -> M
E -> E + E
```

它的解析树是唯一的，即

```
E-------
|  |   |  
1  +   M----
       | | |
       2 * 3
```

## 一些术语定义

- FIRST集合：给定符号串`y`，定义`FIRST(y)`表示所有可能从`y`导出的字符串的第一个符号组成的集合。
- nullable(X)：给定符号`X`，`nullable(X)`为真当且仅当`X`能展开为空字符串
- FOLLOW(X)：给定符号`X`，如果某个终止符`t`，存在某种可能的展开式包含`Xt`，那么`t`属于`FOLLOW(X)`。

如果有多个满足上面条件的FIRST和FOLLOW集合，那么取值为最小的集合。

计算这些集合可以使用不动点算法。

```
For each terminal symbol Z
  FIRST[Z] = {Z}
repeat
  for each production X -> Y[1] Y[2] ... Y[k]
    if Y[1] ... Y[k] are all nullable (or k = 0)
      then nullable[X] = true
    for each i from 1 to k, each j from i + 1 to k
      if Y[1] ... Y[i - 1] are all nullable (or if i = 1)
        then FIRST[X] = FIRST[X] + FIRST[Y[i]]
      if Y[i + 1] ... Y[k] are all nullable (or if i = k)
        then FOLLOW[Y[i]] = FOLLOW[Y[i]] + FOLLOW[X]
      if Y[i + 1] ... Y[j - 1] are all nullable (or if i + 1 = j)
        then FOLLOW[Y[i]] = FOLLOW[Y[i]] + FIRST[Y[j]]
until FIRST, FOLLOW, and nullable did not change in this iteration
```

## LL解析

对于一些简单的语法，如果我们可以通过后一个Token确定唯一的产生式，那么我们可以用递归下降的方式解析Token串。

递归下降能被使用的条件是对于所有的非终止符`X`，以及给定的下一个输入符号`t`，能唯一确定采用某个`X`的产生式。即我们可以通过一个二维表来表达这样的转移关系，这个二维表称为预测解析表（predictive parsing table）。

构建预测解析表的算法：对于产生式`X->y`和每一个`FIRST(y)`中的元素`T`，将产生式加入到预测解析表的第`X`行第`T`列。同样的，如果`y`可空，那么对于每一个`FOLLOW(y)`中的元素`T`，将产生式加入到预测解析表的第`X`行第`T`列。

如果生成的预测解析表中没有重复表项，这样的语法称为`LL(1)`（left-to-right parse, leftmost-derivation, 1-symbol lookahead）。如果我们通过`k`个后继Token的信息构成一个`k+1`维的预测解析表，且表中没有重复表项，这样的语法称为`LL(k)`，`LL(k-1)`语法一定也是`LL(k)`语法。

### 消除左递归

语法如果出现左递归，则一定不是`LL(1)`语法。

```
E -> Eb
E -> a
```

因为`a`一定是`FIRST(Eb)`的元素。可以发现`E=ab*`，我们可以通过一些技巧来消除左递归：

```
E -> aD
D -> bD
D -> 
```

### 左分解

如果语法中存在非终止符，存在两个产生式，拥有非空公共前缀，那么这样的语法一定不是`LL(1)`语法。

```
S -> if E then S else S
S -> if E then S
```

我们可以使用提取公共部分的方法来消除问题

```
S -> if E then S X
X -> else S
X -> 
```

### 错误恢复

一般如果遇到语法错误（输入串不存在于语言中），那么最简单的方式是抛出异常并结束编译。但是这样对用户不友好，因为每次只能报告一个编译错误。有两种可行的恢复编译的方式：

- 插入：插入一个期望的字符，但是这种方式可能会引起另外一个错误，最后导致无限循环
- 删除：删除后续不被期望的字符，这种方式比较安全且简单

## LR解析

LL(k)解析技术的缺点是必须在只有k个输入Token的情况下就必须确定使用某个产生式。LR(k)是一种更加强大的解析技术，它在遇到整个产生式后，并额外读取k个后继Token后才确定使用某个产生式。LR(k)表示left-to-right parse, rightmost-derivation, k-token lookahead。

LR解析算法，维护一个栈和输入，其中输入的前k个Token可以被提前得知。基于栈中和输入的前k个Token的信息，解析器会执行下面两类操作：

- Shift：读取输入的下一个Token，并入栈
- Reduce：选择一个产生式`X->ABC`，从栈中分别弹出`C`，`B`，`A`，之后将`X`入栈。

初始时栈为空，输入为完整的源代码。如果对`$`执行Shift操作，则解析器接受源代码并成功停止。

![https://raw.githubusercontent.com/taodaling/assets/master/images/2022-04-09/parser-grammer-structure.png](https://raw.githubusercontent.com/taodaling/assets/master/images/2022-04-09/parser-grammer-structure.png)

### LR解析引擎

LR解析器如何知道该做什么操作，需要通过一个DFA来实现，并且由于DFA不具有解析上下文无关文法的能力，因此DFA解析的是栈上的数据，而不是输入中的数据。

DFA的边上是可能出现在栈中的符号（终止符和非终止符），通过一个二维表来表示。行为状态，列为input中下一个符号，单元格中保存的是具体执行的操作。操作有如下数类：

- s(n)：执行Shift操作，并转移到状态n
- g(n)：转移到状态n
- r(k)：根据规则k执行reduce操作
- a：接受输入

如果没有标识操作，则代表解析错误。

自动机是从栈底向栈顶解析的，因此如果遇到出栈的时候我们需要恢复自动机的状态，这可以通过记录每个栈中符号对应状态来实现。

### LR(0)

在产生式中，我们向右边加入一个`.`表示当前已经匹配的位置，比如`S'->.S$`。这样形成新的表达式称为item。每个dfa的状态实际上都是一个item集合闭包，即这个集合中如果存在一个状态，`.`在某个非终止符`X`之前，那么`X`的所有产生式对应的`.`在最前的item也都属于这个集合。

需要定义两个关键操作`Closure(I)`和`Goto(I,X)`，前者表示生成`I`的闭包，后者表示集合中所有item中，删除掉`.`后不是`X`的item，并将其余item的`.`后移一位得到的新的集合的闭包。

```
Closure(I):

repeat
  for any item A -> a.Xb in I
    for any production X -> y
      I = I + {X -> .y}
until I does not change
return I
```

```
Goto(I, X):

set J to the empty set
for any item A->a.Xb in I
  add A -> aX.b to J
return Closure(J)
```

下面是构造LR(0)的DFA的算法，计算E集合的算法

```
T = {Closure({S'->.S$})}
E = {}
repeat
  for each state I in T
    for each item A->a.Xb in I
      let J be Goto(I, X)
      T = T + {J}
      E = E + {(I, X, J)}
until E and T did not change in this iteration
```

计算R集合的算法

```
R = {}
for each state I in T
  for each item A -> a. in I
    R = R + {(I, A -> a)}
```

解析表如下：

- 对于每条E中的边(I, X, J)，且X是终止符，在(I, X)处放入shift J操作
- 对于每条E中的边(I, X, J)，且X是非终止符，在(I, X)处放入goto J操作
- 对于每个包含`S'->S.$`的状态`I`，在`(I,$)`放入accept操作。
- 对于R中的任意元素(I, A->a)，对于每个Token Y，在`(I,Y)`中放入`reduce n`操作，其中n是`A->a`的编号。

开始状态为`Closure({S'->.S$})`。

和LL(k)类似，解析表不允许有重复表项，否则就不是一个合法的LR(0)语法。

### SLR

SLR（simple LR）的表达能力比LR(0)更加强大。

SLR的解析表的构建于LR(0)基本没有区别，除了在构建`R`的时候额外使用了FOLLOW集合。

```
R = {}
for each state I in T
  for each item A->a. in I
    for each token X in FOLLOW(A)
      R = R + {(I, X, A->a)}
```

对于R中的任意元素(I, X, A->a)，在`(I,X)`中放入`reduce n`操作，其中n是`A->a`的编号。

SLR的解析表同样不允许有重复表项，否则不是合法的SLR语法。

### LR(1)

LR(1)的item的定义较之LR(0)更加复杂，`(A->a.b,x)`表示序列a处于栈顶，输入的前缀是`bx`的展开式。同理LR(1)中的状态也是item的一个集合闭包。

```
Closure(I):

repeat
  for any item (A->a.Xb, z) in I 
    for any production X->y
      for any w in FIRST(bz)
        I = I + {(X->.y, w)}
until I does not change
return I
```

```
Goto(I, X):

J = {}
for any item (A->a.Xb, z) in I
  J = J + {(A->aX.b, z)}
return Closure(J)
```

开始状态为`(S'->.S$,?)`，其中`?`可以选择任意一个符号。

```
R = {}
for each state I in T
  for each item (A->a., z) in I
    R = R + {(I, z, A->a)}
```

构建E的算法于LR(0)是相同的。

### LALR(1)

LR(1)的解析表可能会非常庞大。如果我们通过将LR(1)中在不考虑lookahead符号的情况下相同的状态进行合并来减少解析表的大小，则可以得到LALR(1)解析技术（lookahead LR(1)）。

LALR(1)相较于LR(1)的表达能力会有所下降，但是在实践上可以忽略不记，所有合理的编程语言都存在LALR(1)语法，然而在存储上LALR(1)会比LR(1)小很多。

### 错误恢复

一种简单的错误修复的方式是选择之前解析的15个Token，选择一个Token，尝试一次插入、删除、替换操作，并统计在执行了每个修复操作后最多能额外解析多少个新的Token，选择解析最多的那个方案。考虑总共有$N$种Token，则只需要尝试$15(2N+1)$种可能性而已。



# Java实践

- [JavaCC](https://javacc.github.io/javacc/)

# 参考资料

- 《Modern Compiler Implementation in Java》