---
categories: algorithm
layout: post
---

- Table
{:toc}

# 线性一致性

线性一致性用来描述我们的分布式系统多么接近一台高性能单机应用，其正式定义如下：

- 操作具有全序性
- 顺序符合实时顺序
- 读操作返回最后写入值

# zookeeper

要实现线性一致性，raft我们需要通过leader节点来执行读操作，但是这就导致了写入和读取不能水平扩容的问题。事实上由于写入必须经由leader节点，因此随着机器的增加，写入的吞吐量反而会下降（需要更多节点组成多数派）。

zookeeper通过违背线性一致性，提供了一种新的一致性，从而得到了读水平扩容的能力。

- 线性化写入（所有写入都通过leader节点并以相同的顺序复制到不同机器上）
- 抛弃读取的线性一致性，提供FIFO客户端序（相同客户端提交的请求，较晚的请求可以看到较早的请求的结果，即在日志中的相对顺序是有序的）
    - 读取操作可以看到同一客户端之前的写操作结果
    - 读取操作看到的已提交日志的前缀

其具体原理是，zookeeper客户端执行写入操作，leader只有在写入提交后才会响应客户端，同时返回写入的日志索引zxid。之后客户端执行读取操作时，可以路由到任意的节点上进行，不过读取操作会带上最后一次写入操作返回的zxid，而节点直到接收并提交了zxid的日志项之后才会执行这个读取操作。

在zookeeper中，提供了watch机制，客户端可以在读某个key的同时在key上放置watcher，watcher会在之后对这个key的修改发生后立即发送（在任何后续写入前发生）。我们可以根据watch实现原子性，客户端A在写入key1，key2，而客户端B需要读取key1，key2。为了保证原子性，客户端A的代码为

```java
del("ready")
write(key1, ...)
write(key2, ...)
create("ready")
```

客户端B的代码为

```java
if(exist("ready", watcher)) {
    read(key1)
    read(key2)

    if watcher get notified {
        restart the whole process
    }
}
```

# 链式复制

实现复制状态机有两种方式，一种是通过raft/paxos等一致性算法，由leader节点向follower节点拷贝日志。这种方式的缺点在于不适合存储大量的数据，以及提供高吞吐的读写操作。第二种方式就是通过协调服务（zookeeper或类似的一致性服务）+主从备份。第二种方法在业界得到广泛的应用。

具体来说，就是假设有三台服务构成主从关系，由协调服务为每个服务分配一个唯一递增编号，最小编号的服务即使master，分别记作S1，S2，S3。拷贝关系见下图

```
S1 --> S2 --> S3
```

且所有写操作发生在S1，而所有读操作发生在S3。一旦某个日志被复制到S3，则认为该日志提交成功。

链式复制能很简单处理宕机的问题，任意机器的下线，只需要简单地把它从链中剔除，由原来的机器按序组成新的链即可。

对于新加入节点，我们不能直接将它作为尾部节点，因为它的数据过度落后，这会导致检查点前移的问题。因此新加入节点应该从当前尾节点进行复制，直到得到了所有的更新，之后才能成为尾节点。

链式复制的性质：

- 实现了读写分离。
- 每个节点最多只需要向一个节点拷贝数据。
- N个节点之间只需要建立N个TCP连接。
- 简单的宕机和恢复操作
- 任意节点下线都会导致链条的重建，这段期间写操作需要被block，导致短时间的整体服务不可用。

链式复制存在一个扩展，允许随着机器的增加实现水平扩容。具体就是构建多条chain，每条chain的首尾节点尽量不同，之后对数据进行切片，让数据落在某一条chain上。这样读写流量就能均分到所有机器上。这种情况下，每条单独的链表都能保证各自的线性一致性。

由于所有写操作必须等待尾部节点接受到对应的日志后才能返回，因此写操作会有额外的延迟。但是一般链式复制只会引入少数的节点，因此延迟一般是可以接受的。（实际上超过2个节点后，只能提高容错能力，并不能提高性能）

# 缓存一致性

Frangipani是一个分布式文件系统，和常规的CS架构不同，它采用文件存储和文件读写分离的方式，即客户端负责IO的逻辑，而文件存储只负责存储块数据。

设计这样的文件系统存在以下挑战

- 缓存一致性
- 写入的原子性
- 操作过程中宕机后能恢复

实现缓存一致性，Frangipani通过一个分布式服务维护一张lock表（锁服务），其中记录每个文件和文件的所有者。并且每个工作站维护一张文件表，其中包含每个缓存在本地的文件的状态，busy或者idle。工作站在修改一个文件之前，需要获得这个文件对应的锁。在一个工作站WS1需要修改或读取某个文件的时候，需要请求锁服务，如果此时文件被另外一台工作站WS2所获得，锁服务会请求WS2要求取回锁，WS2需要将自己的变动写入到分布式文件存储后再释放锁。

原子性同样通过锁互斥来保证。

宕机后恢复通过使用write-ahead logging来保证，将每一步操作记录到日志中（记录发生在执行操作之前）。至于如何保证日志的写入是原子的，基本方式就是写入的同时将校验和也一同写入。在宕机重启后，demon服务会读取WAL并应用所有的更改。

日志的内容为，块号，版本号，和新的数据，以及校验和。版本号用来避免宕机重演日志时覆盖宕机后发生的变更，对同一个文件块的修改会递增文件块的版本号。

在缓存回写的过程中，首先将日志发送到文件存储，之后发送更新的文件块。日志重做时可能是发生在一台不同的机器上。

# 分布式事务

分布式事务追求的一致性目标称为可序列化。可序列化是指多个事务的执行结果一定等同于按某种顺序逐一执行这些事务（不过多个并发的事务之间的执行顺序不保证）。可序列化不保证实时性，因此弱于线性一致性。

要保证可序列化的方式称为并发控制。并发控制的方案有
- 悲观（锁）
- 乐观（如果不可序列化则终止事务）

悲观锁分为
- 两阶段锁
- 两阶段提交

两阶段锁为每一条记录建立一把锁。两条标准
- 线程在使用记录前获得对应的锁。
- 直到提交，线程才释放锁。

两阶段锁是细粒度锁，它并不一次性获得所有需要的锁，而是在事务执行过程中按需获得锁，因此它的并发度会更高。也由于这个原因，它可能会导致死锁。判断死锁的方式有两种
- 超时机制
- 等待图是否有环

两阶段提交是指客户端将要执行的分布式事务提交给协调器，由协调器控制不同的服务完成事务。协调者发送操作要求服务将操作写入到日志中，之后对所有服务调用prepare请求，判断它们是否有能力提交日志（这时候服务要获取所有所需的锁）。如果所有服务都prepare好了，则发送commit请求给服务来提交事务。

为了能保证宕机恢复，参与者和协调器必须所有操作写入日志。由于协调者的宕机都会导致其余所有参与者的等待，因此常见的方式是用raft实现协调者的高可用。

如果任意一个参与服务没有prepare好，则放弃提交，终止事务。如果所有某个参与服务prepare好了但是随后宕机，则重启后必须恢复原来的状态（获得所需的锁，重新进入prepare状态），等待协调者重试。

由于两阶段提交要求参与者必须将日志落盘，而磁盘的WPS往往只有1000，这也导致一台机器的事务上限只能达到1000/s。

